#!/usr/bin/env python3
"""
Extract P0-3 content and apply L4 Safety fixes
"""
import re
import json
from pathlib import Path


def extract_json_blocks(md_content):
    """Extract all JSON blocks from markdown content"""
    pattern = r'```json\s*\n(.*?)\n```'
    matches = re.findall(pattern, md_content, re.DOTALL)
    
    json_blocks = []
    for match in matches:
        try:
            data = json.loads(match)
            json_blocks.append(data)
        except json.JSONDecodeError as e:
            print(f"Warning: Invalid JSON block skipped: {str(e)[:100]}")
            continue
    
    return json_blocks


def apply_l4_safety_fixes(data, facet_id, file_type):
    """Apply L4 Safety fixes to JSON data"""
    data_str = json.dumps(data, ensure_ascii=False)
    
    # Global replacements
    replacements = [
        ("ç„¦æ…®", "ä¸å®‰"),
        ("Burnout", "å…¨é¢è€—ç«­"),
        ("ç¥ç¶“è¡°å¼±", "ç²¾ç¥è² è·éé‡"),
        ("è¡€å£“", "å£“åŠ›è² è·"),
        ("è¨˜æ†¶åŠ›èˆ‡èªçŸ¥èƒ½åŠ›", "æ€ç·’æ•´åˆåº¦"),
        ("èº«é«”æ©Ÿèƒ½", "æ—¥å¸¸é‹ä½œç‹€æ…‹"),
        ("èº«é«”å‡ºç¾è«åç–¼ç—›", "å…§åœ¨è² æ“”å¤–é¡¯"),
    ]
    
    for old, new in replacements:
        data_str = data_str.replace(old, new)
    
    # Facet-specific fixes
    if facet_id == "sleep_rhythm_chaos" and file_type == "recommendations":
        data_str = data_str.replace(
            "æ™šä¸Šç”¨ç†±æ°´æ³¡è…³æˆ–æ´—ç†±æ°´æ¾¡ï¼Œå¼•å°æ°£è¡€ä¸‹è¡Œ",
            "ç¡å‰å®‰æ’å›ºå®šçš„ä½åˆºæ¿€æ”¶å°¾æµç¨‹ï¼Œè®“å¤œæ™šè‡ªç„¶æ²‰éœä¸‹ä¾†"
        )
        data_str = data_str.replace(
            "ç¡ä¸è‘—å°±é›¢é–‹åºŠé‹ªï¼Œç›´åˆ°æœ‰ç¡æ„å†å›å»",
            "è‹¥å¤œæ™šç¯€å¥æ··äº‚ï¼Œæš«æ™‚è½‰æ›ç’°å¢ƒï¼Œç­‰å…§åœ¨ç¯€å¥æ”¾ç·©å†å›åˆ°ä¼‘æ¯ç‹€æ…‹"
        )
    
    if facet_id == "anger_dysregulation" and file_type == "recommendations":
        data_str = data_str.replace(
            "å»æ´—æ‰‹é–“æ½‘å†·æ°´è‡‰",
            "æš«æ™‚è½‰æ›ç©ºé–“ï¼Œç”¨ç’°å¢ƒè®ŠåŒ–ä¸­æ–·ç•¶ä¸‹çš„è¡å‹•ç¯€å¥"
        )
        data_str = data_str.replace(
            "ç”¨åŠ›æ¡ç·Šæ‹³é ­å†æ”¾é–‹",
            "é€éé‡è¤‡çš„ç°¡å–®å‹•ä½œï¼Œå°‡æ³¨æ„åŠ›å¾è¡çªä¸­æŠ½é›¢"
        )
        data_str = data_str.replace(
            "é€²è¡Œç™¼æ´©æ€§çš„æ‹æ‰“",
            "ç”¨å®‰å…¨ä¸”ä¸å‚·å®³ä»»ä½•äººçš„æ–¹å¼é‡‹æ”¾ç´¯ç©çš„èƒ½é‡"
        )
    
    if facet_id == "resentment_buildup" and file_type == "recommendations":
        data_str = data_str.replace(
            "é€²è¡Œé«˜å¼·åº¦çš„é«”èƒ½æ´»å‹•ï¼Œå°‡é«”å…§é¬±æ°£æ’å‡º",
            "å®‰æ’èƒ½å¤§é‡æ¶ˆè€—ç²¾åŠ›çš„æ—¥å¸¸æ´»å‹•ï¼Œè®“ç©å£“çš„èƒ½é‡è‡ªç„¶æ•£å»"
        )
    
    if facet_id == "guilt_accumulation" and file_type == "riskchains":
        data_str = data_str.replace(
            "æ°£æ©Ÿé˜»æ»¯ â†’ èº«é«”å‡ºç¾è«åç–¼ç—›",
            "æ°£æ©Ÿé˜»æ»¯ â†’ å…§åœ¨å£“åŠ›æŒçºŒå †ç©ä¸¦å¤–é¡¯"
        )
    
    if facet_id == "anger_dysregulation" and file_type == "riskchains":
        data_str = data_str.replace(
            "è¡€å£“é•·æœŸæ³¢å‹• â†’ èº«é«”è² æ“”åŠ é‡",
            "å£“åŠ›é•·æœŸèµ·ä¼ â†’ æ•´é«”æ‰¿è¼‰è² è·æŒçºŒä¸Šå‡"
        )
    
    if facet_id == "perfectionism_paralysis" and file_type == "riskchains":
        data_str = data_str.replace(
            "å…¨é¢å´©æ½°ï¼ˆBurnoutï¼‰ â†’ å¼·åˆ¶åœæ©Ÿ",
            "å…¨é¢è€—ç«­ â†’ è¢«è¿«å…¨é¢åœæ“ºï¼ˆæƒ¡æ€§å¾ªç’°ï¼‰"
        )
    
    if facet_id == "impostor_syndrome" and file_type == "riskchains":
        data_str = data_str.replace(
            "ç¥ç¶“è¡°å¼± â†’ è¡¨ç¾å¤±å¸¸",
            "é•·æœŸç²¾ç¥è² è·éé‡ â†’ ç™¼æ®ç©©å®šåº¦ä¸‹é™"
        )
    
    if facet_id == "digital_dissociation" and file_type == "recommendations":
        data_str = data_str.replace(
            "èµ¤è…³è¸©è¸åœ°æ¿æˆ–è‰åœ°ï¼Œæ„Ÿå—è§¸è¦º",
            "åˆ»æ„ç•™æ„èˆ‡ç¾å¯¦ç’°å¢ƒçš„æ¥è§¸ç´°ç¯€ï¼Œå¼·åŒ–ç•¶ä¸‹æ„Ÿ"
        )
        data_str = data_str.replace(
            "é€²è¡Œå†·ç†±æ°´äº¤æ›¿çš„æ´—æ¾¡æˆ–æ´—è‡‰",
            "é€éæ˜é¡¯çš„ç’°å¢ƒç¯€å¥è®ŠåŒ–ï¼Œå–šå›å°ç¾å¯¦çš„æ„ŸçŸ¥"
        )
    
    if facet_id == "digital_dissociation" and file_type == "riskchains":
        data_str = data_str.replace(
            "è¨˜æ†¶åŠ›èˆ‡èªçŸ¥èƒ½åŠ›è¡°é€€ â†’ ç”Ÿæ´»åŠŸèƒ½å—æ",
            "æ€ç·’æ•´åˆåº¦ä¸‹é™ â†’ æ—¥å¸¸é‹ä½œè®Šå¾—æ–·è£‚"
        )
    
    if facet_id == "grief_stagnation" and file_type == "riskchains":
        data_str = data_str.replace(
            "èº«é«”æ©Ÿèƒ½è¡°é€€",
            "æ•´é«”ç”Ÿæ´»ç¯€å¥é€æ¼¸å¤±å»æ”¯æ’"
        )
    
    return json.loads(data_str)


def process_p0_3(md_path, recommendations_dir, narratives_dir, riskchains_dir):
    """Process P0-3 submission with L4 Safety fixes"""
    with open(md_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    json_blocks = extract_json_blocks(content)
    
    print(f"\n=== P0-3 Processing with L4 Safety Fixes ===")
    print(f"Found {len(json_blocks)} JSON blocks")
    
    # Expected: 14 facets Ã— 3 files = 42 JSON blocks
    # Order: recommendations, narratives, riskchains (repeat for each facet)
    
    facet_order = [
        "trust_erosion",
        "attachment_rupture",
        "betrayal_wound",
        "sleep_rhythm_chaos",
        "anger_dysregulation",
        "resentment_buildup",
        "shame_spiral",
        "guilt_accumulation",
        "perfectionism_paralysis",
        "impostor_syndrome",
        "grief_stagnation",
        "apathy_stagnation",
        "purpose_drift",
        "digital_dissociation"
    ]
    
    if len(json_blocks) < 42:
        print(f"âŒ ERROR: Expected at least 42 JSON blocks, got {len(json_blocks)}")
        return []
    
    # Take only the first 42 JSON blocks (main content)
    # The rest might be examples or audit content
    json_blocks = json_blocks[:42]
    print(f"Using first 42 JSON blocks for main content")
    
    written_files = []
    
    print("\n--- Writing Files with L4 Safety Fixes ---")
    
    for i, facet_id in enumerate(facet_order):
        base_idx = i * 3
        
        # Recommendations
        reco_data = json_blocks[base_idx]
        reco_data = apply_l4_safety_fixes(reco_data, facet_id, "recommendations")
        reco_path = recommendations_dir / f"{facet_id}.reco.v1.0.json"
        with open(reco_path, 'w', encoding='utf-8') as f:
            json.dump(reco_data, f, ensure_ascii=False, indent=2)
        print(f"  âœ… {reco_path.name} (recommendations)")
        written_files.append(str(reco_path))
        
        # Narratives
        narr_data = json_blocks[base_idx + 1]
        narr_data = apply_l4_safety_fixes(narr_data, facet_id, "narratives")
        narr_path = narratives_dir / f"{facet_id}.narr.v1.0.json"
        with open(narr_path, 'w', encoding='utf-8') as f:
            json.dump(narr_data, f, ensure_ascii=False, indent=2)
        print(f"  âœ… {narr_path.name} (narratives)")
        written_files.append(str(narr_path))
        
        # Riskchains
        risk_data = json_blocks[base_idx + 2]
        risk_data = apply_l4_safety_fixes(risk_data, facet_id, "riskchains")
        risk_path = riskchains_dir / f"{facet_id}.risk.v1.0.json"
        with open(risk_path, 'w', encoding='utf-8') as f:
            json.dump(risk_data, f, ensure_ascii=False, indent=2)
        print(f"  âœ… {risk_path.name} (riskchains)")
        written_files.append(str(risk_path))
    
    return written_files


if __name__ == "__main__":
    md_file = Path('p0-3.md')
    recommendations_dir = Path('domain/recommendations')
    narratives_dir = Path('domain/narratives')
    riskchains_dir = Path('domain/riskchains')
    
    recommendations_dir.mkdir(parents=True, exist_ok=True)
    narratives_dir.mkdir(parents=True, exist_ok=True)
    riskchains_dir.mkdir(parents=True, exist_ok=True)
    
    written = process_p0_3(md_file, recommendations_dir, narratives_dir, riskchains_dir)
    
    print(f"\nâœ… Total files written: {len(written)}")
    print(f"âœ… Recommendations: {recommendations_dir}")
    print(f"âœ… Narratives: {narratives_dir}")
    print(f"âœ… Riskchains: {riskchains_dir}")
    
    if len(written) == 42:
        print(f"\nğŸŠ P0-3 content extraction complete with L4 Safety fixes!")
        print(f"   All 14 Facets now have complete user-facing content")
    else:
        print(f"\nâš ï¸  Warning: Expected 42 files, wrote {len(written)}")
